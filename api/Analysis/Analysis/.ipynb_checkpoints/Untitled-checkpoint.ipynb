{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      closed       0.46      0.75      0.57         8\n",
      "      opened       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.50        18\n",
      "   macro avg       0.53      0.53      0.49        18\n",
      "weighted avg       0.54      0.50      0.48        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "\n",
    "# store dataset in a variable\n",
    "dataSens = 'dataSensors.csv'\n",
    "# create dataframe & delete all NaN value\n",
    "df = pd.read_csv(dataSens,sep=\";\") # .fillna('')\n",
    "\n",
    "#Activity recognition implementation\n",
    "# convert status_windows in opened || closed\n",
    "df.loc[df['status_windows'] == \"ON\",  'status_windows'] = \"opened\"\n",
    "df.loc[df['status_windows'] == \"OFF\", 'status_windows'] = \"closed\"\n",
    "\n",
    "#take entire string, extract the seconds  and put new value in the 'time' column\n",
    "df['time'] = [int(x[13:]) for x in df['time']]\n",
    "#filter all NaN value\n",
    "df_NoNan = df.dropna()\n",
    "\n",
    "#new dataframe without time\n",
    "df1 = df_NoNan[['volt','time','status_windows',]].reset_index()\n",
    "df2 = df1[['volt','time','status_windows']]\n",
    "#get total duration of status windows  \n",
    "df2['total_seconds'] = abs(df2['time'] - df2['time'].shift(-1))\n",
    "\n",
    "# print(df2)\n",
    "#statical analysis\n",
    "df2['status_windows'].value_counts()\n",
    "\n",
    "# print(df2.describe())\n",
    "\n",
    "#scatter plot\n",
    "# df2.plot(kind = 'scatter', \n",
    "#                  x = 'total_seconds', \n",
    "#                  y = 'volt') \n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "\n",
    "#seaborn scatterplot\n",
    "\n",
    "# sns.set(style = 'whitegrid')\n",
    "# sns.FacetGrid(df2, hue = 'status_windows', height = 6) \\\n",
    "#  .map(plt.scatter, 'total_seconds', 'volt') \\\n",
    "#  .add_legend()\n",
    "# plt.show()\n",
    "\n",
    "  \n",
    "# plotting correlation heatmap\n",
    "# dataplot=sns.heatmap(df2.corr())\n",
    "# displaying heatmap\n",
    "# plt.show()\n",
    "\n",
    "# linear regression case Opened and closed\n",
    "# sns.regplot(x = \"total_seconds\",\n",
    "#             y = \"volt\", \n",
    "#             ci = None,\n",
    "#             data = df2)\n",
    "\n",
    "#linear regression for Closed & Opened cases\n",
    "#filter data set with only \n",
    "# df3 = df2.loc[df2['status_windows']=='closed'][:-1]\n",
    "# sns.regplot(x = \"total_seconds\",\n",
    "#             y = \"volt\", \n",
    "#             ci = None,\n",
    "#             data = df3)\n",
    "\n",
    "# print(df3)\n",
    "\n",
    "#random forest\n",
    "#define series\n",
    "X_df = df2['volt'][:-1].values\n",
    "X_reshape = X_df.reshape((-1,1))\n",
    "X = X_reshape\n",
    "\n",
    "Y_df = df2['total_seconds'][:-1].values\n",
    "Y_reshape = Y_df.reshape((-1,1))\n",
    "y = Y_reshape\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2[:-1].drop('status_windows', 1),\n",
    "                                                    df2['status_windows'][:-1],\n",
    "                                                    test_size = .4, random_state=1000)\n",
    "\n",
    "# creation model\n",
    "model = RandomForestClassifier(max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions for the test set\n",
    "estimator = model.estimators_[1]\n",
    "# features = [i for i in X_train]\n",
    "# y_train_str = y_train.astype('str')\n",
    "# # condition \n",
    "# y_train_str[y_train_str == 'opened'] = y_train_str+': Volt value decreasing'\n",
    "# y_train_str[y_train_str == 'closed'] = y_train_str+':  Volt value increasing'\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# View accuracy score\n",
    "accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# View the classification report for test data and predictions\n",
    "# print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# View the classification report for test data and predictions\n",
    "# print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "#AUC score \n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# roc_auc_score(X_train,y_test )\n",
    "\n",
    "\n",
    "# plot Tree \n",
    "# y_train_str = y_train_str.values\n",
    "# export_graphviz(estimator, out_file='treeTestNew.dot', \n",
    "#                 feature_names = features,\n",
    "#                 class_names = y_train_str, \n",
    "#                 proportion = True, \n",
    "#                 label='root',\n",
    "#                 precision = 2, filled = True\n",
    "\n",
    "\n",
    "\n",
    "# View the classification report for test data and predictions\n",
    "# print(classification_report(y_test))\n",
    "\n",
    "#score importance values assignment \n",
    "# x = df2[:-1].drop(columns = ['total_seconds'])\n",
    "# y = df2['total_seconds'][:-1]\n",
    "\n",
    "# model = linear_model.LinearRegression()\n",
    "\n",
    "# model.fit(x,y)\n",
    "\n",
    "# #prediction\n",
    "\n",
    "# predictions = model.predict(x)\n",
    "\n",
    "# actuals = y.values\n",
    "\n",
    "# mae =0\n",
    "\n",
    "# for i in range(0,len(predictions)):\n",
    "#     prediction = predictions[i]\n",
    "#     actual = actuals[i]\n",
    "#     abs_error = prediction - actual\n",
    "#     mae = mae + abs_error\n",
    "\n",
    "# mae = mae/len(predictions)\n",
    "\n",
    "# print(\"mae: \",mae)\n",
    "# print(\"mean: \",actuals.mean())\n",
    "# print(\"mae mean ratio: \",100*mae/actuals.mean(),'%') \n",
    "\n",
    "# #equation\n",
    "\n",
    "# intercept = model.intercept_\n",
    "# print('model :',model)\n",
    "\n",
    "# coefficients = model.coef_\n",
    "\n",
    "\n",
    "# print(\"y =\",intercept,\"+\",end=\"\")\n",
    "\n",
    "# for i in range(0,len(coefficient)):\n",
    "#         print(coefficient[i], \"X\",i,\" +\",end=\"\")\n",
    "        \n",
    "# print(\" E\")\n",
    "\n",
    "# features = pd.DataFrame(coefficients,x.columns,columns=[\"coefficients\"])\n",
    "\n",
    "# features.coefficients = features.coefficients.abs()\n",
    "\n",
    "# stdevs = []\n",
    "\n",
    "# for i in x.columns:\n",
    "#     stdev = df2[i].std()\n",
    "#     print(i,\"->\",stdev)\n",
    "#     stdevs.append(stdev)\n",
    "\n",
    "# stdevs\n",
    "\n",
    "# features[\"std\"] = np.array(stdevs).reshape(-1,1)\n",
    "# features[\"importance\"] = features[\"std\"]*features[\"coefficients\"]\n",
    "# features[\"importance_normalized\"] = 100*features[\"importance\"] / features[\"importance\"].max()\n",
    "\n",
    "# features\n",
    "\n",
    "# plt.barh(features.index,features.importance_normalized)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
